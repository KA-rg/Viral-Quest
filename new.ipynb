{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8b3f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JSON Query to graphql/query: 403 Forbidden when accessing https://www.instagram.com/graphql/query [retrying; skip with ^C]\n",
      "JSON Query to graphql/query: 401 Unauthorized - \"fail\" status, message \"Please wait a few minutes before you try again.\" when accessing https://www.instagram.com/graphql/query?variables=%7B%22data%22%3A%7B%22count%22%3A12%2C%22include_relationship_info%22%3Atrue%2C%22latest_besties_reel_media%22%3Atrue%2C%22latest_reel_media%22%3Atrue%7D%2C%22username%22%3A%22instagram%22%2C%22__relay_internal__pv__PolarisFeedShareMenurelayprovider%22%3Afalse%7D&doc_id=7898261790222653&server_timestamps=true [retrying; skip with ^C]\n"
     ]
    },
    {
     "ename": "ConnectionException",
     "evalue": "JSON Query to graphql/query: 401 Unauthorized - \"fail\" status, message \"Please wait a few minutes before you try again.\" when accessing https://www.instagram.com/graphql/query?variables=%7B%22data%22%3A%7B%22count%22%3A12%2C%22include_relationship_info%22%3Atrue%2C%22latest_besties_reel_media%22%3Atrue%2C%22latest_reel_media%22%3Atrue%7D%2C%22username%22%3A%22instagram%22%2C%22__relay_internal__pv__PolarisFeedShareMenurelayprovider%22%3Afalse%7D&doc_id=7898261790222653&server_timestamps=true",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\Lib\\site-packages\\instaloader\\instaloadercontext.py:456\u001b[0m, in \u001b[0;36mInstaloaderContext.get_json\u001b[1;34m(self, path, params, host, session, _attempt, response_headers, use_post)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectionException(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_error(resp))\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mConnectionException\u001b[0m: 403 Forbidden when accessing https://www.instagram.com/graphql/query",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\Lib\\site-packages\\instaloader\\instaloadercontext.py:456\u001b[0m, in \u001b[0;36mInstaloaderContext.get_json\u001b[1;34m(self, path, params, host, session, _attempt, response_headers, use_post)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectionException(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_error(resp))\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mConnectionException\u001b[0m: 401 Unauthorized - \"fail\" status, message \"Please wait a few minutes before you try again.\" when accessing https://www.instagram.com/graphql/query?variables=%7B%22data%22%3A%7B%22count%22%3A12%2C%22include_relationship_info%22%3Atrue%2C%22latest_besties_reel_media%22%3Atrue%2C%22latest_reel_media%22%3Atrue%7D%2C%22username%22%3A%22instagram%22%2C%22__relay_internal__pv__PolarisFeedShareMenurelayprovider%22%3Afalse%7D&doc_id=7898261790222653&server_timestamps=true",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\Lib\\site-packages\\instaloader\\instaloadercontext.py:456\u001b[0m, in \u001b[0;36mInstaloaderContext.get_json\u001b[1;34m(self, path, params, host, session, _attempt, response_headers, use_post)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectionException(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_error(resp))\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mConnectionException\u001b[0m: 401 Unauthorized - \"fail\" status, message \"Please wait a few minutes before you try again.\" when accessing https://www.instagram.com/graphql/query?variables=%7B%22data%22%3A%7B%22count%22%3A12%2C%22include_relationship_info%22%3Atrue%2C%22latest_besties_reel_media%22%3Atrue%2C%22latest_reel_media%22%3Atrue%7D%2C%22username%22%3A%22instagram%22%2C%22__relay_internal__pv__PolarisFeedShareMenurelayprovider%22%3Afalse%7D&doc_id=7898261790222653&server_timestamps=true",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mConnectionException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 204\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# Example: replace with your own account\u001b[39;00m\n\u001b[0;32m    202\u001b[0m args \u001b[38;5;241m=\u001b[39m Args(username\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstagram\u001b[39m\u001b[38;5;124m'\u001b[39m, max_posts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m--> 204\u001b[0m posts \u001b[38;5;241m=\u001b[39m get_posts_instaloader(args\u001b[38;5;241m.\u001b[39musername,\n\u001b[0;32m    205\u001b[0m                               max_posts\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mmax_posts,\n\u001b[0;32m    206\u001b[0m                               login_user\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlogin_user,\n\u001b[0;32m    207\u001b[0m                               login_pass\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlogin_pass)\n\u001b[0;32m    208\u001b[0m rows \u001b[38;5;241m=\u001b[39m analyse_posts(posts, args\u001b[38;5;241m.\u001b[39mout)\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCSV saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 95\u001b[0m, in \u001b[0;36mget_posts_instaloader\u001b[1;34m(username, max_posts, login_user, login_pass)\u001b[0m\n\u001b[0;32m     93\u001b[0m profile \u001b[38;5;241m=\u001b[39m instaloader\u001b[38;5;241m.\u001b[39mProfile\u001b[38;5;241m.\u001b[39mfrom_username(L\u001b[38;5;241m.\u001b[39mcontext, username)\n\u001b[0;32m     94\u001b[0m posts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, post \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(profile\u001b[38;5;241m.\u001b[39mget_posts(), total\u001b[38;5;241m=\u001b[39mmax_posts)):\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m max_posts:\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\Lib\\site-packages\\instaloader\\structures.py:1200\u001b[0m, in \u001b[0;36mProfile.get_posts\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Retrieve all posts from a profile.\u001b[39;00m\n\u001b[0;32m   1197\u001b[0m \n\u001b[0;32m   1198\u001b[0m \u001b[38;5;124;03m:rtype: NodeIterator[Post]\"\"\"\u001b[39;00m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obtain_metadata()\n\u001b[1;32m-> 1200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m NodeIterator(\n\u001b[0;32m   1201\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context,\n\u001b[0;32m   1202\u001b[0m     edge_extractor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m d: d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxdt_api__v1__feed__user_timeline_graphql_connection\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   1203\u001b[0m     node_wrapper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m n: Post\u001b[38;5;241m.\u001b[39mfrom_iphone_struct(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context, n),\n\u001b[0;32m   1204\u001b[0m     query_variables \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m   1205\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m12\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_relationship_info\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1206\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest_besties_reel_media\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest_reel_media\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m},\n\u001b[0;32m   1207\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124musername\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musername},\n\u001b[0;32m   1208\u001b[0m     query_referer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.instagram.com/\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39musername),\n\u001b[0;32m   1209\u001b[0m     is_first \u001b[38;5;241m=\u001b[39m Profile\u001b[38;5;241m.\u001b[39m_make_is_newest_checker(),\n\u001b[0;32m   1210\u001b[0m     doc_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m7898261790222653\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1211\u001b[0m     query_hash \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1212\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\Lib\\site-packages\\instaloader\\nodeiterator.py:100\u001b[0m, in \u001b[0;36mNodeIterator.__init__\u001b[1;34m(self, context, query_hash, edge_extractor, node_wrapper, query_variables, query_referer, first_data, is_first, doc_id)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_before \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m+\u001b[39m NodeIterator\u001b[38;5;241m.\u001b[39m_shelf_life\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query()\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_node: Optional[Dict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_first \u001b[38;5;241m=\u001b[39m is_first\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\Lib\\site-packages\\instaloader\\nodeiterator.py:106\u001b[0m, in \u001b[0;36mNodeIterator._query\u001b[1;34m(self, after)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, after: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict:\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_doc_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_doc_id(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_doc_id, after)\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\Lib\\site-packages\\instaloader\\nodeiterator.py:119\u001b[0m, in \u001b[0;36mNodeIterator._query_doc_id\u001b[1;34m(self, doc_id, after)\u001b[0m\n\u001b[0;32m    116\u001b[0m     pagination_variables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[0;32m    117\u001b[0m     pagination_variables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    118\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edge_extractor(\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mdoc_id_graphql_query(\n\u001b[0;32m    120\u001b[0m         doc_id, {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_variables, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpagination_variables}, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query_referer\n\u001b[0;32m    121\u001b[0m     )\n\u001b[0;32m    122\u001b[0m )\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_before \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m+\u001b[39m NodeIterator\u001b[38;5;241m.\u001b[39m_shelf_life\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\Lib\\site-packages\\instaloader\\instaloadercontext.py:543\u001b[0m, in \u001b[0;36mInstaloaderContext.doc_id_graphql_query\u001b[1;34m(self, doc_id, variables, referer)\u001b[0m\n\u001b[0;32m    539\u001b[0m         tmpsession\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreferer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39mquote(referer)\n\u001b[0;32m    541\u001b[0m     variables_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(variables, separators\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m--> 543\u001b[0m     resp_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_json(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraphql/query\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    544\u001b[0m                               params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariables\u001b[39m\u001b[38;5;124m'\u001b[39m: variables_json,\n\u001b[0;32m    545\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoc_id\u001b[39m\u001b[38;5;124m'\u001b[39m: doc_id,\n\u001b[0;32m    546\u001b[0m                                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserver_timestamps\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m},\n\u001b[0;32m    547\u001b[0m                               session\u001b[38;5;241m=\u001b[39mtmpsession,\n\u001b[0;32m    548\u001b[0m                               use_post\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m resp_json:\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraphQL response did not contain a \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m field.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\Lib\\site-packages\\instaloader\\instaloadercontext.py:480\u001b[0m, in \u001b[0;36mInstaloaderContext.get_json\u001b[1;34m(self, path, params, host, session, _attempt, response_headers, use_post)\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_other_query:\n\u001b[0;32m    479\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rate_controller\u001b[38;5;241m.\u001b[39mhandle_429(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mother\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_json(path\u001b[38;5;241m=\u001b[39mpath, params\u001b[38;5;241m=\u001b[39mparams, host\u001b[38;5;241m=\u001b[39mhost, session\u001b[38;5;241m=\u001b[39msess, _attempt\u001b[38;5;241m=\u001b[39m_attempt \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    481\u001b[0m                          response_headers\u001b[38;5;241m=\u001b[39mresponse_headers)\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[skipped by user]\u001b[39m\u001b[38;5;124m\"\u001b[39m, repeat_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\Lib\\site-packages\\instaloader\\instaloadercontext.py:480\u001b[0m, in \u001b[0;36mInstaloaderContext.get_json\u001b[1;34m(self, path, params, host, session, _attempt, response_headers, use_post)\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m is_other_query:\n\u001b[0;32m    479\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rate_controller\u001b[38;5;241m.\u001b[39mhandle_429(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mother\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_json(path\u001b[38;5;241m=\u001b[39mpath, params\u001b[38;5;241m=\u001b[39mparams, host\u001b[38;5;241m=\u001b[39mhost, session\u001b[38;5;241m=\u001b[39msess, _attempt\u001b[38;5;241m=\u001b[39m_attempt \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    481\u001b[0m                          response_headers\u001b[38;5;241m=\u001b[39mresponse_headers)\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[skipped by user]\u001b[39m\u001b[38;5;124m\"\u001b[39m, repeat_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\krish\\anaconda3\\Lib\\site-packages\\instaloader\\instaloadercontext.py:468\u001b[0m, in \u001b[0;36mInstaloaderContext.get_json\u001b[1;34m(self, path, params, host, session, _attempt, response_headers, use_post)\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m QueryReturnedNotFoundException(error_string) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 468\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ConnectionException(error_string) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror(error_string \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [retrying; skip with ^C]\u001b[39m\u001b[38;5;124m\"\u001b[39m, repeat_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mConnectionException\u001b[0m: JSON Query to graphql/query: 401 Unauthorized - \"fail\" status, message \"Please wait a few minutes before you try again.\" when accessing https://www.instagram.com/graphql/query?variables=%7B%22data%22%3A%7B%22count%22%3A12%2C%22include_relationship_info%22%3Atrue%2C%22latest_besties_reel_media%22%3Atrue%2C%22latest_reel_media%22%3Atrue%7D%2C%22username%22%3A%22instagram%22%2C%22__relay_internal__pv__PolarisFeedShareMenurelayprovider%22%3Afalse%7D&doc_id=7898261790222653&server_timestamps=true"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "from statistics import mean\n",
    "from collections import Counter\n",
    "\n",
    "import instaloader\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "\n",
    "# Optional: for video meta\n",
    "try:\n",
    "    from moviepy.editor import VideoFileClip\n",
    "    MOVIEPY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MOVIEPY_AVAILABLE = False\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "MAX_COMMENTS_PER_POST = 50\n",
    "MOOD_LABELS = [\"motivation\", \"comedy\", \"brainrot\", \"informative\"]\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "def extract_hashtags(text):\n",
    "    return re.findall(r\"#(\\w+)\", text or \"\")\n",
    "\n",
    "def init_pipelines():\n",
    "    \"\"\"Load ML models lazily.\"\"\"\n",
    "    global mood_pipeline, sentiment_pipeline\n",
    "    if \"mood_pipeline\" not in globals():\n",
    "        print(\"Loading transformers pipelines …\")\n",
    "        mood_pipeline = pipeline(\"zero-shot-classification\",\n",
    "                                 model=\"facebook/bart-large-mnli\")\n",
    "        sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "def classify_mood(text):\n",
    "    if not text.strip():\n",
    "        return None\n",
    "    out = mood_pipeline(text, candidate_labels=MOOD_LABELS)\n",
    "    return out[\"labels\"][0]\n",
    "\n",
    "def analyse_comment_tone(comments):\n",
    "    \"\"\"Return counts of sentiment labels.\"\"\"\n",
    "    if not comments:\n",
    "        return {}\n",
    "    texts = [c[\"text\"] for c in comments if c[\"text\"]]\n",
    "    if not texts:\n",
    "        return {}\n",
    "    results = sentiment_pipeline(texts)\n",
    "    counts = Counter(r[\"label\"] for r in results)\n",
    "    return dict(counts)\n",
    "\n",
    "def download_and_get_video_meta(url):\n",
    "    \"\"\"Download a video temporarily and return duration, first-3s hook metric.\"\"\"\n",
    "    if not MOVIEPY_AVAILABLE or not url:\n",
    "        return None, None\n",
    "    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\")\n",
    "    try:\n",
    "        import requests\n",
    "        r = requests.get(url, stream=True)\n",
    "        for chunk in r.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                tmp.write(chunk)\n",
    "        tmp.close()\n",
    "        clip = VideoFileClip(tmp.name)\n",
    "        duration = clip.duration\n",
    "        # naive \"hook performance\" = ratio of first 3 s to total length\n",
    "        hook_ratio = min(3, duration) / duration\n",
    "        clip.close()\n",
    "        return duration, hook_ratio\n",
    "    except Exception:\n",
    "        return None, None\n",
    "    finally:\n",
    "        try:\n",
    "            os.remove(tmp.name)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "# -----------------------\n",
    "# Instagram fetch\n",
    "# -----------------------\n",
    "def get_posts_instaloader(username, max_posts=20, login_user=None, login_pass=None):\n",
    "    L = instaloader.Instaloader(download_videos=False,\n",
    "                                save_metadata=False,\n",
    "                                download_comments=False)\n",
    "    if login_user and login_pass:\n",
    "        L.login(login_user, login_pass)\n",
    "    profile = instaloader.Profile.from_username(L.context, username)\n",
    "    posts = []\n",
    "    for i, post in enumerate(tqdm(profile.get_posts(), total=max_posts)):\n",
    "        if i >= max_posts:\n",
    "            break\n",
    "        data = {\n",
    "            \"id\": str(post.mediaid),\n",
    "            \"shortcode\": post.shortcode,\n",
    "            \"caption\": post.caption or \"\",\n",
    "            \"hashtags\": extract_hashtags(post.caption or \"\"),\n",
    "            \"likes\": post.likes,\n",
    "            \"comments_count\": post.comments_count,\n",
    "            \"is_video\": post.is_video,\n",
    "            \"display_url\": post.url,\n",
    "            \"video_url\": post.video_url if post.is_video else None,\n",
    "            \"timestamp\": post.date_utc.isoformat(),\n",
    "            # New fields\n",
    "            \"location\": post.location.name if post.location else None,\n",
    "            \"music_title\": None,   # Placeholder (needs Graph API)\n",
    "            \"shares\": None,        # Placeholder (needs Graph API)\n",
    "            \"saves\": None,         # Placeholder (needs Graph API)\n",
    "        }\n",
    "        comments = []\n",
    "        try:\n",
    "            for c in post.get_comments():\n",
    "                comments.append({\n",
    "                    \"text\": getattr(c, \"text\", \"\"),\n",
    "                    \"owner\": getattr(getattr(c, \"owner\", None), \"username\", None)\n",
    "                })\n",
    "                if len(comments) >= MAX_COMMENTS_PER_POST:\n",
    "                    break\n",
    "        except Exception:\n",
    "            pass\n",
    "        data[\"comments\"] = comments\n",
    "        posts.append(data)\n",
    "    return posts\n",
    "\n",
    "# -----------------------\n",
    "# Main analysis\n",
    "# -----------------------\n",
    "def analyse_posts(posts, csv_path):\n",
    "    init_pipelines()\n",
    "    rows = []\n",
    "    for p in tqdm(posts, desc=\"Analysing\"):\n",
    "        mood = classify_mood(p[\"caption\"])\n",
    "        tone_counts = analyse_comment_tone(p[\"comments\"])\n",
    "        duration, hook_ratio = (None, None)\n",
    "        if p[\"is_video\"]:\n",
    "            duration, hook_ratio = download_and_get_video_meta(p[\"video_url\"])\n",
    "        rows.append({\n",
    "            \"id\": p[\"id\"],\n",
    "            \"shortcode\": p[\"shortcode\"],\n",
    "            \"timestamp\": p[\"timestamp\"],\n",
    "            \"likes\": p[\"likes\"],\n",
    "            \"comments_count\": p[\"comments_count\"],\n",
    "            \"shares\": p[\"shares\"],\n",
    "            \"saves\": p[\"saves\"],\n",
    "            \"caption\": p[\"caption\"],\n",
    "            \"hashtags\": \",\".join(p[\"hashtags\"]),\n",
    "            \"mood\": mood,\n",
    "            \"comment_tone\": tone_counts,\n",
    "            \"video_duration\": duration,\n",
    "            \"hook_ratio_first3s\": hook_ratio,\n",
    "            \"location\": p[\"location\"],\n",
    "            \"music_title\": p[\"music_title\"],\n",
    "        })\n",
    "    # write CSV\n",
    "    keys = rows[0].keys()\n",
    "    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        for r in rows:\n",
    "            writer.writerow(r)\n",
    "    return rows\n",
    "\n",
    "def print_suggestions(rows):\n",
    "    # Basic insights\n",
    "    moods = [r[\"mood\"] for r in rows if r[\"mood\"]]\n",
    "    most_common_mood = Counter(moods).most_common(1)\n",
    "    hashtags = [h for r in rows for h in (r[\"hashtags\"].split(\",\") if r[\"hashtags\"] else [])]\n",
    "    top_hashtags = [h for h, _ in Counter(hashtags).most_common(5)]\n",
    "    avg_hook = mean([r[\"hook_ratio_first3s\"] for r in rows if r[\"hook_ratio_first3s\"]]) \\\n",
    "               if any(r[\"hook_ratio_first3s\"] for r in rows) else None\n",
    "\n",
    "    print(\"\\n--- Suggestions ---\")\n",
    "    if most_common_mood:\n",
    "        print(f\"• Most frequent mood detected: {most_common_mood[0][0]}\")\n",
    "    if top_hashtags:\n",
    "        print(f\"• Top hashtags to refine around: {', '.join(top_hashtags)}\")\n",
    "    if avg_hook:\n",
    "        print(f\"• Average first-3-seconds hook ratio: {avg_hook:.2f}\")\n",
    "        if avg_hook < 0.2:\n",
    "            print(\"  Consider stronger hooks or A/B thumbnails.\")\n",
    "    print(\"• Post when your audience is most active (use IG Insights to get actual active hours).\")\n",
    "    print(\"• Tailor colour palette & fonts to the dominant mood for stronger branding.\")\n",
    "\n",
    "# -----------------------\n",
    "# Run\n",
    "# -----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    class Args:\n",
    "        def __init__(self, username, max_posts=10, login_user=None, login_pass=None, out=\"ig_posts.csv\"):\n",
    "            self.username = username\n",
    "            self.max_posts = max_posts\n",
    "            self.login_user = login_user\n",
    "            self.login_pass = login_pass\n",
    "            self.out = out\n",
    "\n",
    "    # Example: replace with your own account\n",
    "    args = Args(username='instagram', max_posts=5)\n",
    "\n",
    "    posts = get_posts_instaloader(args.username,\n",
    "                                  max_posts=args.max_posts,\n",
    "                                  login_user=args.login_user,\n",
    "                                  login_pass=args.login_pass)\n",
    "    rows = analyse_posts(posts, args.out)\n",
    "    print(f\"\\nCSV saved to {args.out}\")\n",
    "    print_suggestions(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04bc4252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "from collections import Counter\n",
    "from statistics import mean\n",
    "from tqdm import tqdm\n",
    "\n",
    "ACCESS_TOKEN = \"YOUR_ACCESS_TOKEN\"\n",
    "IG_USER_ID = \"YOUR_IG_USER_ID\"  # numeric ID\n",
    "MAX_POSTS = 10\n",
    "\n",
    "# Define fields to fetch\n",
    "FIELDS = (\n",
    "    \"id,caption,media_type,media_url,permalink,timestamp,\"\n",
    "    \"like_count,comments_count,thumbnail_url,children{media_url,media_type},\"\n",
    "    \"insights.metric(reach,saved,impressions)\"\n",
    ")\n",
    "\n",
    "def fetch_posts(user_id, access_token, max_posts=10):\n",
    "    url = f\"https://graph.facebook.com/v17.0/{user_id}/media\"\n",
    "    params = {\n",
    "        \"fields\": FIELDS,\n",
    "        \"access_token\": access_token,\n",
    "        \"limit\": max_posts\n",
    "    }\n",
    "\n",
    "    posts = []\n",
    "    r = requests.get(url, params=params).json()\n",
    "\n",
    "    for item in r.get(\"data\", []):\n",
    "        posts.append({\n",
    "            \"id\": item.get(\"id\"),\n",
    "            \"caption\": item.get(\"caption\", \"\"),\n",
    "            \"media_type\": item.get(\"media_type\"),\n",
    "            \"media_url\": item.get(\"media_url\"),\n",
    "            \"permalink\": item.get(\"permalink\"),\n",
    "            \"timestamp\": item.get(\"timestamp\"),\n",
    "            \"likes\": item.get(\"like_count\"),\n",
    "            \"comments_count\": item.get(\"comments_count\"),\n",
    "            \"saves\": None,  # Can get from insights\n",
    "            \"reach\": None,  # Can get from insights\n",
    "        })\n",
    "\n",
    "    return posts\n",
    "\n",
    "# -----------------------\n",
    "# Example CSV Export\n",
    "# -----------------------\n",
    "def save_to_csv(posts, path=\"ig_graph_api_posts.csv\"):\n",
    "    if not posts:\n",
    "        return\n",
    "    keys = posts[0].keys()\n",
    "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        for p in posts:\n",
    "            writer.writerow(p)\n",
    "    print(f\"CSV saved to {path}\")\n",
    "\n",
    "# -----------------------\n",
    "# Run\n",
    "# -----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    posts = fetch_posts(IG_USER_ID, ACCESS_TOKEN, max_posts=MAX_POSTS)\n",
    "    save_to_csv(posts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fff8d3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --username USERNAME [--max_posts MAX_POSTS]\n",
      "                             [--login_user LOGIN_USER]\n",
      "                             [--login_pass LOGIN_PASS] [--out OUT]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --username\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\krish\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import tempfile\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from statistics import mean\n",
    "from collections import Counter\n",
    "\n",
    "import instaloader\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "\n",
    "# Optional: for video meta\n",
    "try:\n",
    "    from moviepy.editor import VideoFileClip\n",
    "    MOVIEPY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MOVIEPY_AVAILABLE = False\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "MAX_COMMENTS_PER_POST = 50\n",
    "MOOD_LABELS = [\"motivation\", \"comedy\", \"brainrot\", \"informative\"]\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "def extract_hashtags(text):\n",
    "    return re.findall(r\"#(\\w+)\", text or \"\")\n",
    "\n",
    "def init_pipelines():\n",
    "    \"\"\"Load ML models lazily.\"\"\"\n",
    "    global mood_pipeline, sentiment_pipeline\n",
    "    if \"mood_pipeline\" not in globals():\n",
    "        print(\"Loading transformers pipelines …\")\n",
    "        mood_pipeline = pipeline(\"zero-shot-classification\",\n",
    "                                 model=\"facebook/bart-large-mnli\")\n",
    "        sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "def classify_mood(text):\n",
    "    if not text or not text.strip():\n",
    "        return None\n",
    "    try:\n",
    "        out = mood_pipeline(text, candidate_labels=MOOD_LABELS)\n",
    "        return out[\"labels\"][0]\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def analyse_comment_tone(comments):\n",
    "    \"\"\"Return counts of sentiment labels.\"\"\"\n",
    "    if not comments:\n",
    "        return {}\n",
    "    texts = [c[\"text\"] for c in comments if c[\"text\"]]\n",
    "    if not texts:\n",
    "        return {}\n",
    "    try:\n",
    "        results = sentiment_pipeline(texts)\n",
    "        counts = Counter(r[\"label\"] for r in results)\n",
    "        return dict(counts)\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "def download_and_get_video_meta(url):\n",
    "    \"\"\"Download a video temporarily and return duration, first-3s hook metric.\"\"\"\n",
    "    if not MOVIEPY_AVAILABLE or not url:\n",
    "        return None, None\n",
    "    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\")\n",
    "    try:\n",
    "        import requests\n",
    "        r = requests.get(url, stream=True, timeout=15)\n",
    "        for chunk in r.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                tmp.write(chunk)\n",
    "        tmp.close()\n",
    "        clip = VideoFileClip(tmp.name)\n",
    "        duration = clip.duration\n",
    "        # naive \"hook performance\" = ratio of first 3 s to total length\n",
    "        hook_ratio = min(3, duration) / duration\n",
    "        clip.close()\n",
    "        return duration, hook_ratio\n",
    "    except Exception:\n",
    "        return None, None\n",
    "    finally:\n",
    "        try:\n",
    "            os.remove(tmp.name)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "# -----------------------\n",
    "# Instagram fetch\n",
    "# -----------------------\n",
    "def get_posts_instaloader(username, max_posts=20, login_user=None, login_pass=None):\n",
    "    L = instaloader.Instaloader(download_videos=False,\n",
    "                                save_metadata=False,\n",
    "                                download_comments=False)\n",
    "    if login_user and login_pass:\n",
    "        L.login(login_user, login_pass)\n",
    "    profile = instaloader.Profile.from_username(L.context, username)\n",
    "    posts = []\n",
    "    for i, post in enumerate(tqdm(profile.get_posts(), total=max_posts, desc=\"Fetching posts\")):\n",
    "        if i >= max_posts:\n",
    "            break\n",
    "        data = {\n",
    "            \"id\": str(post.mediaid),\n",
    "            \"shortcode\": post.shortcode,\n",
    "            \"caption\": post.caption or \"\",\n",
    "            \"hashtags\": extract_hashtags(post.caption or \"\"),\n",
    "            \"likes\": post.likes,\n",
    "            \"comments_count\": post.comments_count,\n",
    "            \"is_video\": post.is_video,\n",
    "            \"display_url\": post.url,\n",
    "            \"video_url\": post.video_url if post.is_video else None,\n",
    "            \"timestamp\": post.date_utc.isoformat(),\n",
    "            # New fields (placeholders)\n",
    "            \"location\": post.location.name if post.location else None,\n",
    "            \"music_title\": None,   # Needs Graph API\n",
    "            \"shares\": None,        # Needs Graph API\n",
    "            \"saves\": None,         # Needs Graph API\n",
    "        }\n",
    "        comments = []\n",
    "        try:\n",
    "            for c in post.get_comments():\n",
    "                comments.append({\n",
    "                    \"text\": getattr(c, \"text\", \"\"),\n",
    "                    \"owner\": getattr(getattr(c, \"owner\", None), \"username\", None)\n",
    "                })\n",
    "                if len(comments) >= MAX_COMMENTS_PER_POST:\n",
    "                    break\n",
    "        except Exception:\n",
    "            pass\n",
    "        data[\"comments\"] = comments\n",
    "        posts.append(data)\n",
    "    return posts\n",
    "\n",
    "# -----------------------\n",
    "# Main analysis\n",
    "# -----------------------\n",
    "def analyse_posts(posts, csv_path):\n",
    "    init_pipelines()\n",
    "    rows = []\n",
    "    for p in tqdm(posts, desc=\"Analysing\"):\n",
    "        mood = classify_mood(p[\"caption\"])\n",
    "        tone_counts = analyse_comment_tone(p[\"comments\"])\n",
    "        duration, hook_ratio = (None, None)\n",
    "        if p[\"is_video\"]:\n",
    "            duration, hook_ratio = download_and_get_video_meta(p[\"video_url\"])\n",
    "        rows.append({\n",
    "            \"id\": p[\"id\"],\n",
    "            \"shortcode\": p[\"shortcode\"],\n",
    "            \"timestamp\": p[\"timestamp\"],\n",
    "            \"likes\": p[\"likes\"],\n",
    "            \"comments_count\": p[\"comments_count\"],\n",
    "            \"shares\": p[\"shares\"],\n",
    "            \"saves\": p[\"saves\"],\n",
    "            \"caption\": p[\"caption\"],\n",
    "            \"hashtags\": \",\".join(p[\"hashtags\"]),\n",
    "            \"mood\": mood,\n",
    "            \"comment_tone\": json.dumps(tone_counts, ensure_ascii=False),\n",
    "            \"video_duration\": duration,\n",
    "            \"hook_ratio_first3s\": hook_ratio,\n",
    "            \"location\": p[\"location\"],\n",
    "            \"music_title\": p[\"music_title\"],\n",
    "        })\n",
    "    # write CSV\n",
    "    keys = [\"id\", \"shortcode\", \"timestamp\", \"likes\", \"comments_count\",\n",
    "            \"shares\", \"saves\", \"caption\", \"hashtags\", \"mood\",\n",
    "            \"comment_tone\", \"video_duration\", \"hook_ratio_first3s\",\n",
    "            \"location\", \"music_title\"]\n",
    "    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=keys)\n",
    "        writer.writeheader()\n",
    "        for r in rows:\n",
    "            writer.writerow(r)\n",
    "    return rows\n",
    "\n",
    "def print_suggestions(rows):\n",
    "    moods = [r[\"mood\"] for r in rows if r[\"mood\"]]\n",
    "    most_common_mood = Counter(moods).most_common(1)\n",
    "    hashtags = [h for r in rows for h in (r[\"hashtags\"].split(\",\") if r[\"hashtags\"] else [])]\n",
    "    top_hashtags = [h for h, _ in Counter(hashtags).most_common(5)]\n",
    "    avg_hook = mean([r[\"hook_ratio_first3s\"] for r in rows if r[\"hook_ratio_first3s\"]]) \\\n",
    "               if any(r[\"hook_ratio_first3s\"] for r in rows) else None\n",
    "\n",
    "    print(\"\\n--- Suggestions ---\")\n",
    "    if most_common_mood:\n",
    "        print(f\"• Most frequent mood detected: {most_common_mood[0][0]}\")\n",
    "    if top_hashtags:\n",
    "        print(f\"• Top hashtags to refine around: {', '.join(top_hashtags)}\")\n",
    "    if avg_hook:\n",
    "        print(f\"• Average first-3-seconds hook ratio: {avg_hook:.2f}\")\n",
    "        if avg_hook < 0.2:\n",
    "            print(\"  ⚠️ Consider stronger hooks or better thumbnails.\")\n",
    "    print(\"• Post when your audience is most active (use IG Insights for best timing).\")\n",
    "    print(\"• Tailor colour palette & fonts to the dominant mood for stronger branding.\")\n",
    "\n",
    "# -----------------------\n",
    "# Run\n",
    "# -----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Instagram Post Analyzer (Hackathon Ready)\")\n",
    "    parser.add_argument(\"--username\", required=True, help=\"Instagram username\")\n",
    "    parser.add_argument(\"--max_posts\", type=int, default=10, help=\"Max posts to fetch\")\n",
    "    parser.add_argument(\"--login_user\", help=\"Login username (optional)\")\n",
    "    parser.add_argument(\"--login_pass\", help=\"Login password (optional)\")\n",
    "    parser.add_argument(\"--out\", default=\"ig_posts.csv\", help=\"Output CSV path\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    posts = get_posts_instaloader(args.username,\n",
    "                                  max_posts=args.max_posts,\n",
    "                                  login_user=args.login_user,\n",
    "                                  login_pass=args.login_pass)\n",
    "    rows = analyse_posts(posts, args.out)\n",
    "    print(f\"\\n✅ CSV saved to {args.out}\")\n",
    "    print_suggestions(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc004626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: instaloader in c:\\users\\krish\\anaconda3\\lib\\site-packages (4.14.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\krish\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Collecting moviepy\n",
      "  Downloading moviepy-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\krish\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from moviepy) (5.1.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from moviepy) (2.33.1)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
      "  Downloading imageio_ffmpeg-0.6.0-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numpy>=1.25.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from moviepy) (1.26.4)\n",
      "Collecting proglog<=1.0.0 (from moviepy)\n",
      "  Downloading proglog-0.1.12-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from moviepy) (0.21.0)\n",
      "Requirement already satisfied: pillow<12.0,>=9.2.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from moviepy) (10.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Downloading moviepy-2.2.1-py3-none-any.whl (129 kB)\n",
      "Downloading imageio_ffmpeg-0.6.0-py3-none-win_amd64.whl (31.2 MB)\n",
      "   ---------------------------------------- 0.0/31.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.1/31.2 MB 11.8 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 8.9/31.2 MB 23.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 15.5/31.2 MB 25.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 20.4/31.2 MB 25.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 26.2/31.2 MB 25.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  31.2/31.2 MB 26.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 31.2/31.2 MB 24.2 MB/s eta 0:00:00\n",
      "Downloading proglog-0.1.12-py3-none-any.whl (6.3 kB)\n",
      "Installing collected packages: imageio_ffmpeg, proglog, moviepy\n",
      "Successfully installed imageio_ffmpeg-0.6.0 moviepy-2.2.1 proglog-0.1.12\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install instaloader tqdm moviepy requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afa71e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp312-cp312-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\krish\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.35.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\krish\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\krish\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\krish\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\krish\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\krish\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/11.6 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.3/11.6 MB 22.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 22.7 MB/s eta 0:00:00\n",
      "Downloading torch-2.8.0-cp312-cp312-win_amd64.whl (241.3 MB)\n",
      "   ---------------------------------------- 0.0/241.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 4.7/241.3 MB 25.9 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 10.5/241.3 MB 25.2 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 17.0/241.3 MB 26.8 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 23.1/241.3 MB 27.5 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 28.3/241.3 MB 27.2 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 34.1/241.3 MB 27.1 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 40.1/241.3 MB 26.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 46.4/241.3 MB 27.1 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 52.2/241.3 MB 27.0 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 58.2/241.3 MB 27.3 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 64.0/241.3 MB 27.2 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 70.3/241.3 MB 27.3 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 76.5/241.3 MB 27.4 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 82.8/241.3 MB 27.5 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 89.7/241.3 MB 27.8 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 95.9/241.3 MB 27.8 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 102.5/241.3 MB 28.0 MB/s eta 0:00:05\n",
      "   ----------------- --------------------- 108.5/241.3 MB 27.9 MB/s eta 0:00:05\n",
      "   ------------------ -------------------- 114.3/241.3 MB 28.0 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 120.3/241.3 MB 27.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 126.4/241.3 MB 28.0 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 132.9/241.3 MB 28.1 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 138.9/241.3 MB 28.1 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 144.7/241.3 MB 28.1 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 151.0/241.3 MB 28.0 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 157.3/241.3 MB 28.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 163.8/241.3 MB 28.1 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 169.9/241.3 MB 28.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 175.6/241.3 MB 28.1 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 180.1/241.3 MB 27.9 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 183.2/241.3 MB 27.4 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 185.6/241.3 MB 27.0 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 188.5/241.3 MB 26.5 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 191.1/241.3 MB 26.1 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 197.4/241.3 MB 26.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 203.4/241.3 MB 26.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 209.7/241.3 MB 26.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 215.7/241.3 MB 26.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 218.1/241.3 MB 26.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 223.6/241.3 MB 25.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 229.4/241.3 MB 25.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 234.6/241.3 MB 26.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  237.2/241.3 MB 25.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 25.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 25.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 25.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 25.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 25.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 25.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 241.3/241.3 MB 22.7 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.35.0-py3-none-any.whl (563 kB)\n",
      "   ---------------------------------------- 0.0/563.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 563.4/563.4 kB 9.7 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   -------------------------------------- - 6.0/6.3 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 22.7 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 22.1 MB/s eta 0:00:00\n",
      "Installing collected packages: sympy, safetensors, torch, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "Successfully installed huggingface-hub-0.35.0 safetensors-0.6.2 sympy-1.14.0 tokenizers-0.22.1 torch-2.8.0 transformers-4.56.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c0e19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting instaloader\n",
      "  Downloading instaloader-4.14.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: requests>=2.25 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from instaloader) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests>=2.25->instaloader) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests>=2.25->instaloader) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests>=2.25->instaloader) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\krish\\anaconda3\\lib\\site-packages (from requests>=2.25->instaloader) (2024.8.30)\n",
      "Downloading instaloader-4.14.2-py3-none-any.whl (67 kB)\n",
      "Installing collected packages: instaloader\n",
      "Successfully installed instaloader-4.14.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install instaloader\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
